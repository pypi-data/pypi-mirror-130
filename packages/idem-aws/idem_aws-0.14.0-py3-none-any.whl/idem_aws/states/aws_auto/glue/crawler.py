"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.glue.create_crawler
hub.exec.boto3.client.glue.delete_crawler
hub.exec.boto3.client.glue.get_crawlers
hub.exec.boto3.client.glue.list_crawlers
hub.exec.boto3.client.glue.start_crawler
hub.exec.boto3.client.glue.stop_crawler
hub.exec.boto3.client.glue.update_crawler
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, role: Text, targets: Dict, database_name: Text = None, description: Text = None, schedule: Text = None, classifiers: List = None, table_prefix: Text = None, schema_change_policy: Dict = None, recrawl_policy: Dict = None, lineage_configuration: Dict = None, configuration: Text = None, crawler_security_configuration: Text = None, tags: Dict = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates a new crawler with specified targets, role, configuration, and optional schedule. At least one crawl
    target must be specified, in the s3Targets field, the jdbcTargets field, or the DynamoDBTargets field.

    Args:
        name(Text): Name of the new crawler.
        role(Text): The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler to access
            customer resources.
        database_name(Text, optional): The Glue database where results are written, such as: arn:aws:daylight:us-
            east-1::database/sometable/*. Defaults to None.
        description(Text, optional): A description of the new crawler. Defaults to None.
        targets(Dict): A list of collection of targets to crawl.
        schedule(Text, optional): A cron expression used to specify the schedule (see Time-Based Schedules for Jobs and Crawlers.
            For example, to run something every day at 12:15 UTC, you would specify: cron(15 12 * * ? *). Defaults to None.
        classifiers(List, optional): A list of custom classifiers that the user has registered. By default, all built-in classifiers
            are included in a crawl, but these custom classifiers always override the default classifiers
            for a given classification. Defaults to None.
        table_prefix(Text, optional): The table prefix used for catalog tables that are created. Defaults to None.
        schema_change_policy(Dict, optional): The policy for the crawler's update and deletion behavior. Defaults to None.
        recrawl_policy(Dict, optional): A policy that specifies whether to crawl the entire dataset again, or to crawl only folders that
            were added since the last crawler run. Defaults to None.
        lineage_configuration(Dict, optional): Specifies data lineage configuration settings for the crawler. Defaults to None.
        configuration(Text, optional): Crawler configuration information. This versioned JSON string allows users to specify aspects of
            a crawler's behavior. For more information, see Configuring a Crawler. Defaults to None.
        crawler_security_configuration(Text, optional): The name of the SecurityConfiguration structure to be used by this crawler. Defaults to None.
        tags(Dict, optional): The tags to use with this crawler request. You may use tags to limit access to the crawler. For
            more information about tags in Glue, see Amazon Web Services Tags in Glue in the developer
            guide. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.glue.crawler.present:
                - name: value
                - role: value
                - targets: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.glue.crawler.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.glue.get_crawlers(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.glue.create_crawler(
                ctx,
                
                
                **{"Name": name, "Role": role, "DatabaseName": database_name, "Description": description, "Targets": targets, "Schedule": schedule, "Classifiers": classifiers, "TablePrefix": table_prefix, "SchemaChangePolicy": schema_change_policy, "RecrawlPolicy": recrawl_policy, "LineageConfiguration": lineage_configuration, "Configuration": configuration, "CrawlerSecurityConfiguration": crawler_security_configuration, "Tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.glue.get_crawlers(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Removes a specified crawler from the Glue Data Catalog, unless the crawler state is RUNNING.

    Args:
        name(Text): The name of the crawler to remove.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.glue.crawler.absent:
                - name: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.glue.crawler.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.glue.get_crawlers(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.glue.delete_crawler(
                ctx,
                
                
                **{"Name": name}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.glue.get_crawlers(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

