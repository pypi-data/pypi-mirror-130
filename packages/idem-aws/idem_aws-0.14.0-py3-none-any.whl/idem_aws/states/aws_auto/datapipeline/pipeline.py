"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.datapipeline.activate_pipeline
hub.exec.boto3.client.datapipeline.create_pipeline
hub.exec.boto3.client.datapipeline.deactivate_pipeline
hub.exec.boto3.client.datapipeline.delete_pipeline
hub.exec.boto3.client.datapipeline.describe_pipelines
hub.exec.boto3.client.datapipeline.list_pipelines
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, unique_id: Text, description: Text = None, tags: List = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates a new, empty pipeline. Use PutPipelineDefinition to populate the pipeline.

    Args:
        name(Text): The name for the pipeline. You can use the same name for multiple pipelines associated with your
            AWS account, because AWS Data Pipeline assigns each pipeline a unique pipeline identifier.
        unique_id(Text): A unique identifier. This identifier is not the same as the pipeline identifier assigned by AWS
            Data Pipeline. You are responsible for defining the format and ensuring the uniqueness of this
            identifier. You use this parameter to ensure idempotency during repeated calls to
            CreatePipeline. For example, if the first call to CreatePipeline does not succeed, you can pass
            in the same unique identifier and pipeline name combination on a subsequent call to
            CreatePipeline. CreatePipeline ensures that if a pipeline already exists with the same name and
            unique identifier, a new pipeline is not created. Instead, you'll receive the pipeline
            identifier from the previous attempt. The uniqueness of the name and unique identifier
            combination is scoped to the AWS account or IAM user credentials.
        description(Text, optional): The description for the pipeline. Defaults to None.
        tags(List, optional): A list of tags to associate with the pipeline at creation. Tags let you control access to
            pipelines. For more information, see Controlling User Access to Pipelines in the AWS Data
            Pipeline Developer Guide. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.datapipeline.pipeline.present:
                - name: value
                - unique_id: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.datapipeline.pipeline.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.datapipeline.describe_pipelines(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.datapipeline.create_pipeline(
                ctx,
                
                
                **{"Name": name, "uniqueId": unique_id, "description": description, "tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.datapipeline.describe_pipelines(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, pipeline_id: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes a pipeline, its pipeline definition, and its run history. AWS Data Pipeline attempts to cancel instances
    associated with the pipeline that are currently being processed by task runners. Deleting a pipeline cannot be
    undone. You cannot query or restore a deleted pipeline. To temporarily pause a pipeline instead of deleting it,
    call SetStatus with the status set to PAUSE on individual components. Components that are paused by SetStatus
    can be resumed.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        pipeline_id(Text): The ID of the pipeline.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.datapipeline.pipeline.absent:
                - name: value
                - pipeline_id: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.datapipeline.pipeline.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.datapipeline.describe_pipelines(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.datapipeline.delete_pipeline(
                ctx,
                
                
                **{"pipelineId": pipeline_id}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.datapipeline.describe_pipelines(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

