"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.machinelearning.create_ml_model
hub.exec.boto3.client.machinelearning.delete_ml_model
hub.exec.boto3.client.machinelearning.describe_ml_models
hub.exec.boto3.client.machinelearning.get_ml_model
hub.exec.boto3.client.machinelearning.update_ml_model
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, ml_model_id: Text, ml_model_type: Text, training_data_source_id: Text, ml_model_name: Text = None, parameters: Dict = None, recipe: Text = None, recipe_uri: Text = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates a new MLModel using the DataSource and the recipe as information sources.  An MLModel is nearly
    immutable. Users can update only the MLModelName and the ScoreThreshold in an MLModel without creating a new
    MLModel.   CreateMLModel is an asynchronous operation. In response to CreateMLModel, Amazon Machine Learning
    (Amazon ML) immediately returns and sets the MLModel status to PENDING. After the MLModel has been created and
    ready is for use, Amazon ML sets the status to COMPLETED.  You can use the GetMLModel operation to check the
    progress of the MLModel during the creation operation.  CreateMLModel requires a DataSource with computed
    statistics, which can be created by setting ComputeStatistics to true in CreateDataSourceFromRDS,
    CreateDataSourceFromS3, or CreateDataSourceFromRedshift operations.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        ml_model_id(Text): A user-supplied ID that uniquely identifies the MLModel.
        ml_model_name(Text, optional): A user-supplied name or description of the MLModel. Defaults to None.
        ml_model_type(Text): The category of supervised learning that this MLModel will address. Choose from the following
            types:   Choose REGRESSION if the MLModel will be used to predict a numeric value.   Choose
            BINARY if the MLModel result has two possible values.   Choose MULTICLASS if the MLModel result
            has a limited number of values.    For more information, see the Amazon Machine Learning
            Developer Guide.
        parameters(Dict, optional): A list of the training parameters in the MLModel. The list is implemented as a map of key-value
            pairs. The following is the current set of training parameters:    sgd.maxMLModelSizeInBytes -
            The maximum allowed size of the model. Depending on the input data, the size of the model might
            affect its performance.  The value is an integer that ranges from 100000 to 2147483648. The
            default value is 33554432.    sgd.maxPasses - The number of times that the training process
            traverses the observations to build the MLModel. The value is an integer that ranges from 1 to
            10000. The default value is 10.    sgd.shuffleType - Whether Amazon ML shuffles the training
            data. Shuffling the data improves a model's ability to find the optimal solution for a variety
            of data types. The valid values are auto and none. The default value is none. We strongly
            recommend that you shuffle your data.    sgd.l1RegularizationAmount - The coefficient
            regularization L1 norm. It controls overfitting the data by penalizing large coefficients. This
            tends to drive coefficients to zero, resulting in a sparse feature set. If you use this
            parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges
            from 0 to MAX_DOUBLE. The default is to not use L1 normalization. This parameter can't be used
            when L2 is specified. Use this parameter sparingly.    sgd.l2RegularizationAmount - The
            coefficient regularization L2 norm. It controls overfitting the data by penalizing large
            coefficients. This tends to drive coefficients to small, nonzero values. If you use this
            parameter, start by specifying a small value, such as 1.0E-08. The value is a double that ranges
            from 0 to MAX_DOUBLE. The default is to not use L2 normalization. This parameter can't be used
            when L1 is specified. Use this parameter sparingly. Defaults to None.
        training_data_source_id(Text): The DataSource that points to the training data.
        recipe(Text, optional): The data recipe for creating the MLModel. You must specify either the recipe or its URI. If you
            don't specify a recipe or its URI, Amazon ML creates a default. Defaults to None.
        recipe_uri(Text, optional): The Amazon Simple Storage Service (Amazon S3) location and file name that contains the MLModel
            recipe. You must specify either the recipe or its URI. If you don't specify a recipe or its URI,
            Amazon ML creates a default. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.machinelearning.ml_model.present:
                - name: value
                - ml_model_id: value
                - ml_model_type: value
                - training_data_source_id: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.machinelearning.ml_model.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.machinelearning.describe_ml_models(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.machinelearning.create_ml_model(
                ctx,
                
                
                **{"MLModelId": ml_model_id, "MLModelName": ml_model_name, "MLModelType": ml_model_type, "Parameters": parameters, "TrainingDataSourceId": training_data_source_id, "Recipe": recipe, "RecipeUri": recipe_uri}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.machinelearning.describe_ml_models(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, ml_model_id: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Assigns the DELETED status to an MLModel, rendering it unusable. After using the DeleteMLModel operation, you
    can use the GetMLModel operation to verify that the status of the MLModel changed to DELETED.  Caution: The
    result of the DeleteMLModel operation is irreversible.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        ml_model_id(Text): A user-supplied ID that uniquely identifies the MLModel.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.machinelearning.ml_model.absent:
                - name: value
                - ml_model_id: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.machinelearning.ml_model.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.machinelearning.describe_ml_models(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.machinelearning.delete_ml_model(
                ctx,
                
                
                **{"MLModelId": ml_model_id}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.machinelearning.describe_ml_models(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

