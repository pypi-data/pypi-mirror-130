"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.machinelearning.create_batch_prediction
hub.exec.boto3.client.machinelearning.delete_batch_prediction
hub.exec.boto3.client.machinelearning.describe_batch_predictions
hub.exec.boto3.client.machinelearning.get_batch_prediction
hub.exec.boto3.client.machinelearning.update_batch_prediction
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, batch_prediction_id: Text, ml_model_id: Text, batch_prediction_data_source_id: Text, output_uri: Text, batch_prediction_name: Text = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Generates predictions for a group of observations. The observations to process exist in one or more data files
    referenced by a DataSource. This operation creates a new BatchPrediction, and uses an MLModel and the data files
    referenced by the DataSource as information sources.   CreateBatchPrediction is an asynchronous operation. In
    response to CreateBatchPrediction, Amazon Machine Learning (Amazon ML) immediately returns and sets the
    BatchPrediction status to PENDING. After the BatchPrediction completes, Amazon ML sets the status to COMPLETED.
    You can poll for status updates by using the GetBatchPrediction operation and checking the Status parameter of
    the result. After the COMPLETED status appears, the results are available in the location specified by the
    OutputUri parameter.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        batch_prediction_id(Text): A user-supplied ID that uniquely identifies the BatchPrediction.
        batch_prediction_name(Text, optional): A user-supplied name or description of the BatchPrediction. BatchPredictionName can only use the
            UTF-8 character set. Defaults to None.
        ml_model_id(Text): The ID of the MLModel that will generate predictions for the group of observations.
        batch_prediction_data_source_id(Text): The ID of the DataSource that points to the group of observations to predict.
        output_uri(Text): The location of an Amazon Simple Storage Service (Amazon S3) bucket or directory to store the
            batch prediction results. The following substrings are not allowed in the s3 key portion of the
            outputURI field: ':', '//', '/./', '/../'. Amazon ML needs permissions to store and retrieve the
            logs on your behalf. For information about how to set permissions, see the Amazon Machine
            Learning Developer Guide.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.machinelearning.batch_prediction.present:
                - name: value
                - batch_prediction_id: value
                - ml_model_id: value
                - batch_prediction_data_source_id: value
                - output_uri: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.machinelearning.batch_prediction.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.machinelearning.describe_batch_predictions(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.machinelearning.create_batch_prediction(
                ctx,
                
                
                **{"BatchPredictionId": batch_prediction_id, "BatchPredictionName": batch_prediction_name, "MLModelId": ml_model_id, "BatchPredictionDataSourceId": batch_prediction_data_source_id, "OutputUri": output_uri}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.machinelearning.describe_batch_predictions(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, batch_prediction_id: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Assigns the DELETED status to a BatchPrediction, rendering it unusable. After using the DeleteBatchPrediction
    operation, you can use the GetBatchPrediction operation to verify that the status of the BatchPrediction changed
    to DELETED.  Caution: The result of the DeleteBatchPrediction operation is irreversible.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        batch_prediction_id(Text): A user-supplied ID that uniquely identifies the BatchPrediction.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.machinelearning.batch_prediction.absent:
                - name: value
                - batch_prediction_id: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.machinelearning.batch_prediction.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.machinelearning.describe_batch_predictions(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.machinelearning.delete_batch_prediction(
                ctx,
                
                
                **{"BatchPredictionId": batch_prediction_id}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.machinelearning.describe_batch_predictions(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

