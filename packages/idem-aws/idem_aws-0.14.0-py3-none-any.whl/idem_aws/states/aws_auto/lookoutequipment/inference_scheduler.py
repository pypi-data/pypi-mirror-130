"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.lookoutequipment.create_inference_scheduler
hub.exec.boto3.client.lookoutequipment.delete_inference_scheduler
hub.exec.boto3.client.lookoutequipment.describe_inference_scheduler
hub.exec.boto3.client.lookoutequipment.list_inference_schedulers
hub.exec.boto3.client.lookoutequipment.start_inference_scheduler
hub.exec.boto3.client.lookoutequipment.stop_inference_scheduler
hub.exec.boto3.client.lookoutequipment.update_inference_scheduler
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, model_name: Text, inference_scheduler_name: Text, data_upload_frequency: Text, data_input_configuration: Dict, data_output_configuration: Dict, role_arn: Text, data_delay_offset_in_minutes: int = None, server_side_kms_key_id: Text = None, tags: List = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
     Creates a scheduled inference. Scheduling an inference is setting up a continuous real-time inference plan to
    analyze new measurement data. When setting up the schedule, you provide an S3 bucket location for the input
    data, assign it a delimiter between separate entries in the data, set an offset delay if desired, and set the
    frequency of inferencing. You must also provide an S3 bucket location for the output data.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        model_name(Text): The name of the previously trained ML model being used to create the inference scheduler.
        inference_scheduler_name(Text): The name of the inference scheduler being created.
        data_delay_offset_in_minutes(int, optional):  A period of time (in minutes) by which inference on the data is delayed after the data starts.
            For instance, if you select an offset delay time of five minutes, inference will not begin on
            the data until the first data measurement after the five minute mark. For example, if five
            minutes is selected, the inference scheduler will wake up at the configured frequency with the
            additional five minute delay time to check the customer S3 bucket. The customer can upload data
            at the same frequency and they don't need to stop and restart the scheduler when uploading new
            data. Defaults to None.
        data_upload_frequency(Text):  How often data is uploaded to the source S3 bucket for the input data. The value chosen is the
            length of time between data uploads. For instance, if you select 5 minutes, Amazon Lookout for
            Equipment will upload the real-time data to the source bucket once every 5 minutes. This
            frequency also determines how often Amazon Lookout for Equipment starts a scheduled inference on
            your data. In this example, it starts once every 5 minutes.
        data_input_configuration(Dict): Specifies configuration information for the input data for the inference scheduler, including
            delimiter, format, and dataset location.
        data_output_configuration(Dict): Specifies configuration information for the output results for the inference scheduler,
            including the S3 location for the output.
        role_arn(Text): The Amazon Resource Name (ARN) of a role with permission to access the data source being used
            for the inference.
        server_side_kms_key_id(Text, optional): Provides the identifier of the AWS KMS customer master key (CMK) used to encrypt inference
            scheduler data by Amazon Lookout for Equipment. Defaults to None.
        tags(List, optional): Any tags associated with the inference scheduler. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.lookoutequipment.inference_scheduler.present:
                - name: value
                - model_name: value
                - inference_scheduler_name: value
                - data_upload_frequency: value
                - data_input_configuration: value
                - data_output_configuration: value
                - role_arn: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.lookoutequipment.inference_scheduler.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.lookoutequipment.describe_inference_scheduler(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.lookoutequipment.create_inference_scheduler(
                ctx,
                
                ClientToken=name,
                **{"ModelName": model_name, "InferenceSchedulerName": inference_scheduler_name, "DataDelayOffsetInMinutes": data_delay_offset_in_minutes, "DataUploadFrequency": data_upload_frequency, "DataInputConfiguration": data_input_configuration, "DataOutputConfiguration": data_output_configuration, "RoleArn": role_arn, "ServerSideKmsKeyId": server_side_kms_key_id, "Tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.lookoutequipment.describe_inference_scheduler(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, inference_scheduler_name: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes an inference scheduler that has been set up. Already processed output results are not affected.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        inference_scheduler_name(Text): The name of the inference scheduler to be deleted.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.lookoutequipment.inference_scheduler.absent:
                - name: value
                - inference_scheduler_name: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.lookoutequipment.inference_scheduler.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.lookoutequipment.describe_inference_scheduler(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.lookoutequipment.delete_inference_scheduler(
                ctx,
                
                
                **{"InferenceSchedulerName": inference_scheduler_name}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.lookoutequipment.describe_inference_scheduler(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

