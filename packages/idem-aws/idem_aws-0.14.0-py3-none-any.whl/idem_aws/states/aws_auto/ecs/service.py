"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.ecs.create_service
hub.exec.boto3.client.ecs.delete_service
hub.exec.boto3.client.ecs.describe_services
hub.exec.boto3.client.ecs.list_services
hub.exec.boto3.client.ecs.update_service
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, service_name: Text, cluster: Text = None, task_definition: Text = None, load_balancers: List = None, service_registries: List = None, desired_count: int = None, client_token: Text = None, launch_type: Text = None, capacity_provider_strategy: List = None, platform_version: Text = None, role: Text = None, deployment_configuration: Dict = None, placement_constraints: List = None, placement_strategy: List = None, network_configuration: Dict = None, health_check_grace_period_seconds: int = None, scheduling_strategy: Text = None, deployment_controller: Dict = None, tags: List = None, enable_ecs_managed_tags: bool = None, propagate_tags: Text = None, enable_execute_command: bool = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Runs and maintains a desired number of tasks from a specified task definition. If the number of tasks running in
    a service drops below the desiredCount, Amazon ECS runs another copy of the task in the specified cluster. To
    update an existing service, see the UpdateService action. In addition to maintaining the desired count of tasks
    in your service, you can optionally run your service behind one or more load balancers. The load balancers
    distribute traffic across the tasks that are associated with the service. For more information, see Service Load
    Balancing in the Amazon Elastic Container Service Developer Guide. Tasks for services that do not use a load
    balancer are considered healthy if they're in the RUNNING state. Tasks for services that do use a load balancer
    are considered healthy if they're in the RUNNING state and the container instance that they're hosted on is
    reported as healthy by the load balancer. There are two service scheduler strategies available:    REPLICA - The
    replica scheduling strategy places and maintains the desired number of tasks across your cluster. By default,
    the service scheduler spreads tasks across Availability Zones. You can use task placement strategies and
    constraints to customize task placement decisions. For more information, see Service Scheduler Concepts in the
    Amazon Elastic Container Service Developer Guide.    DAEMON - The daemon scheduling strategy deploys exactly one
    task on each active container instance that meets all of the task placement constraints that you specify in your
    cluster. The service scheduler also evaluates the task placement constraints for running tasks and will stop
    tasks that do not meet the placement constraints. When using this strategy, you don't need to specify a desired
    number of tasks, a task placement strategy, or use Service Auto Scaling policies. For more information, see
    Service Scheduler Concepts in the Amazon Elastic Container Service Developer Guide.   You can optionally specify
    a deployment configuration for your service. The deployment is triggered by changing properties, such as the
    task definition or the desired count of a service, with an UpdateService operation. The default value for a
    replica service for minimumHealthyPercent is 100%. The default value for a daemon service for
    minimumHealthyPercent is 0%. If a service is using the ECS deployment controller, the minimum healthy percent
    represents a lower limit on the number of tasks in a service that must remain in the RUNNING state during a
    deployment, as a percentage of the desired number of tasks (rounded up to the nearest integer), and while any
    container instances are in the DRAINING state if the service contains tasks using the EC2 launch type. This
    parameter enables you to deploy without using additional cluster capacity. For example, if your service has a
    desired number of four tasks and a minimum healthy percent of 50%, the scheduler might stop two existing tasks
    to free up cluster capacity before starting two new tasks. Tasks for services that do not use a load balancer
    are considered healthy if they're in the RUNNING state. Tasks for services that do use a load balancer are
    considered healthy if they're in the RUNNING state and they're reported as healthy by the load balancer. The
    default value for minimum healthy percent is 100%. If a service is using the ECS deployment controller, the
    maximum percent parameter represents an upper limit on the number of tasks in a service that are allowed in the
    RUNNING or PENDING state during a deployment, as a percentage of the desired number of tasks (rounded down to
    the nearest integer), and while any container instances are in the DRAINING state if the service contains tasks
    using the EC2 launch type. This parameter enables you to define the deployment batch size. For example, if your
    service has a desired number of four tasks and a maximum percent value of 200%, the scheduler may start four new
    tasks before stopping the four older tasks (provided that the cluster resources required to do this are
    available). The default value for maximum percent is 200%. If a service is using either the CODE_DEPLOY or
    EXTERNAL deployment controller types and tasks that use the EC2 launch type, the minimum healthy percent and
    maximum percent values are used only to define the lower and upper limit on the number of the tasks in the
    service that remain in the RUNNING state while the container instances are in the DRAINING state. If the tasks
    in the service use the Fargate launch type, the minimum healthy percent and maximum percent values aren't used,
    although they're currently visible when describing your service. When creating a service that uses the EXTERNAL
    deployment controller, you can specify only parameters that aren't controlled at the task set level. The only
    required parameter is the service name. You control your services using the CreateTaskSet operation. For more
    information, see Amazon ECS Deployment Types in the Amazon Elastic Container Service Developer Guide. When the
    service scheduler launches new tasks, it determines task placement in your cluster using the following logic:
    Determine which of the container instances in your cluster can support your service's task definition (for
    example, they have the required CPU, memory, ports, and container instance attributes).   By default, the
    service scheduler attempts to balance tasks across Availability Zones in this manner (although you can choose a
    different placement strategy) with the placementStrategy parameter):   Sort the valid container instances,
    giving priority to instances that have the fewest number of running tasks for this service in their respective
    Availability Zone. For example, if zone A has one running service task and zones B and C each have zero, valid
    container instances in either zone B or C are considered optimal for placement.   Place the new service task on
    a valid container instance in an optimal Availability Zone (based on the previous steps), favoring container
    instances with the fewest number of running tasks for this service.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        cluster(Text, optional): The short name or full Amazon Resource Name (ARN) of the cluster on which to run your service.
            If you do not specify a cluster, the default cluster is assumed. Defaults to None.
        service_name(Text): The name of your service. Up to 255 letters (uppercase and lowercase), numbers, underscores, and
            hyphens are allowed. Service names must be unique within a cluster, but you can have similarly
            named services in multiple clusters within a Region or across multiple Regions.
        task_definition(Text, optional): The family and revision (family:revision) or full ARN of the task definition to run in your
            service. If a revision is not specified, the latest ACTIVE revision is used. A task definition
            must be specified if the service is using either the ECS or CODE_DEPLOY deployment controllers. Defaults to None.
        load_balancers(List, optional): A load balancer object representing the load balancers to use with your service. For more
            information, see Service Load Balancing in the Amazon Elastic Container Service Developer Guide.
            If the service is using the rolling update (ECS) deployment controller and using either an
            Application Load Balancer or Network Load Balancer, you must specify one or more target group
            ARNs to attach to the service. The service-linked role is required for services that make use of
            multiple target groups. For more information, see Using service-linked roles for Amazon ECS in
            the Amazon Elastic Container Service Developer Guide. If the service is using the CODE_DEPLOY
            deployment controller, the service is required to use either an Application Load Balancer or
            Network Load Balancer. When creating an CodeDeploy deployment group, you specify two target
            groups (referred to as a targetGroupPair). During a deployment, CodeDeploy determines which task
            set in your service has the status PRIMARY and associates one target group with it, and then
            associates the other target group with the replacement task set. The load balancer can also have
            up to two listeners: a required listener for production traffic and an optional listener that
            allows you perform validation tests with Lambda functions before routing production traffic to
            it. After you create a service using the ECS deployment controller, the load balancer name or
            target group ARN, container name, and container port specified in the service definition are
            immutable. If you are using the CODE_DEPLOY deployment controller, these values can be changed
            when updating the service. For Application Load Balancers and Network Load Balancers, this
            object must contain the load balancer target group ARN, the container name (as it appears in a
            container definition), and the container port to access from the load balancer. The load
            balancer name parameter must be omitted. When a task from this service is placed on a container
            instance, the container instance and port combination is registered as a target in the target
            group specified here. For Classic Load Balancers, this object must contain the load balancer
            name, the container name (as it appears in a container definition), and the container port to
            access from the load balancer. The target group ARN parameter must be omitted. When a task from
            this service is placed on a container instance, the container instance is registered with the
            load balancer specified here. Services with tasks that use the awsvpc network mode (for example,
            those with the Fargate launch type) only support Application Load Balancers and Network Load
            Balancers. Classic Load Balancers are not supported. Also, when you create any target groups for
            these services, you must choose ip as the target type, not instance, because tasks that use the
            awsvpc network mode are associated with an elastic network interface, not an Amazon EC2
            instance. Defaults to None.
        service_registries(List, optional): The details of the service discovery registry to associate with this service. For more
            information, see Service discovery.  Each service may be associated with one service registry.
            Multiple service registries per service isn't supported. Defaults to None.
        desired_count(int, optional): The number of instantiations of the specified task definition to place and keep running on your
            cluster. This is required if schedulingStrategy is REPLICA or is not specified. If
            schedulingStrategy is DAEMON then this is not required. Defaults to None.
        client_token(Text, optional): Unique, case-sensitive identifier that you provide to ensure the idempotency of the request. Up
            to 32 ASCII characters are allowed. Defaults to None.
        launch_type(Text, optional): The infrastructure on which to run your service. For more information, see Amazon ECS launch
            types in the Amazon Elastic Container Service Developer Guide. The FARGATE launch type runs your
            tasks on Fargate On-Demand infrastructure.  Fargate Spot infrastructure is available for use but
            a capacity provider strategy must be used. For more information, see Fargate capacity providers
            in the Amazon ECS User Guide for Fargate.  The EC2 launch type runs your tasks on Amazon EC2
            instances registered to your cluster. The EXTERNAL launch type runs your tasks on your on-
            premise server or virtual machine (VM) capacity registered to your cluster. A service can use
            either a launch type or a capacity provider strategy. If a launchType is specified, the
            capacityProviderStrategy parameter must be omitted. Defaults to None.
        capacity_provider_strategy(List, optional): The capacity provider strategy to use for the service. If a capacityProviderStrategy is
            specified, the launchType parameter must be omitted. If no capacityProviderStrategy or
            launchType is specified, the defaultCapacityProviderStrategy for the cluster is used. A capacity
            provider strategy may contain a maximum of 6 capacity providers. Defaults to None.
        platform_version(Text, optional): The platform version that your tasks in the service are running on. A platform version is
            specified only for tasks using the Fargate launch type. If one isn't specified, the LATEST
            platform version is used by default. For more information, see Fargate platform versions in the
            Amazon Elastic Container Service Developer Guide. Defaults to None.
        role(Text, optional): The name or full Amazon Resource Name (ARN) of the IAM role that allows Amazon ECS to make calls
            to your load balancer on your behalf. This parameter is only permitted if you are using a load
            balancer with your service and your task definition does not use the awsvpc network mode. If you
            specify the role parameter, you must also specify a load balancer object with the loadBalancers
            parameter.  If your account has already created the Amazon ECS service-linked role, that role is
            used by default for your service unless you specify a role here. The service-linked role is
            required if your task definition uses the awsvpc network mode or if the service is configured to
            use service discovery, an external deployment controller, multiple target groups, or Elastic
            Inference accelerators in which case you should not specify a role here. For more information,
            see Using service-linked roles for Amazon ECS in the Amazon Elastic Container Service Developer
            Guide.  If your specified role has a path other than /, then you must either specify the full
            role ARN (this is recommended) or prefix the role name with the path. For example, if a role
            with the name bar has a path of /foo/ then you would specify /foo/bar as the role name. For more
            information, see Friendly names and paths in the IAM User Guide. Defaults to None.
        deployment_configuration(Dict, optional): Optional deployment parameters that control how many tasks run during the deployment and the
            ordering of stopping and starting tasks. Defaults to None.
        placement_constraints(List, optional): An array of placement constraint objects to use for tasks in your service. You can specify a
            maximum of 10 constraints per task (this limit includes constraints in the task definition and
            those specified at runtime). Defaults to None.
        placement_strategy(List, optional): The placement strategy objects to use for tasks in your service. You can specify a maximum of 5
            strategy rules per service. Defaults to None.
        network_configuration(Dict, optional): The network configuration for the service. This parameter is required for task definitions that
            use the awsvpc network mode to receive their own elastic network interface, and it is not
            supported for other network modes. For more information, see Task networking in the Amazon
            Elastic Container Service Developer Guide. Defaults to None.
        health_check_grace_period_seconds(int, optional): The period of time, in seconds, that the Amazon ECS service scheduler should ignore unhealthy
            Elastic Load Balancing target health checks after a task has first started. This is only used
            when your service is configured to use a load balancer. If your service has a load balancer
            defined and you don't specify a health check grace period value, the default value of 0 is used.
            If your service's tasks take a while to start and respond to Elastic Load Balancing health
            checks, you can specify a health check grace period of up to 2,147,483,647 seconds. During that
            time, the Amazon ECS service scheduler ignores health check status. This grace period can
            prevent the service scheduler from marking tasks as unhealthy and stopping them before they have
            time to come up. Defaults to None.
        scheduling_strategy(Text, optional): The scheduling strategy to use for the service. For more information, see Services. There are
            two service scheduler strategies available:    REPLICA-The replica scheduling strategy places
            and maintains the desired number of tasks across your cluster. By default, the service scheduler
            spreads tasks across Availability Zones. You can use task placement strategies and constraints
            to customize task placement decisions. This scheduler strategy is required if the service is
            using the CODE_DEPLOY or EXTERNAL deployment controller types.    DAEMON-The daemon scheduling
            strategy deploys exactly one task on each active container instance that meets all of the task
            placement constraints that you specify in your cluster. The service scheduler also evaluates the
            task placement constraints for running tasks and will stop tasks that do not meet the placement
            constraints. When you're using this strategy, you don't need to specify a desired number of
            tasks, a task placement strategy, or use Service Auto Scaling policies.  Tasks using the Fargate
            launch type or the CODE_DEPLOY or EXTERNAL deployment controller types don't support the DAEMON
            scheduling strategy. Defaults to None.
        deployment_controller(Dict, optional): The deployment controller to use for the service. If no deployment controller is specified, the
            default value of ECS is used. Defaults to None.
        tags(List, optional): The metadata that you apply to the service to help you categorize and organize them. Each tag
            consists of a key and an optional value, both of which you define. When a service is deleted,
            the tags are deleted as well. The following basic restrictions apply to tags:   Maximum number
            of tags per resource - 50   For each resource, each tag key must be unique, and each tag key can
            have only one value.   Maximum key length - 128 Unicode characters in UTF-8   Maximum value
            length - 256 Unicode characters in UTF-8   If your tagging schema is used across multiple
            services and resources, remember that other services may have restrictions on allowed
            characters. Generally allowed characters are: letters, numbers, and spaces representable in
            UTF-8, and the following characters: + - = . _ : / @.   Tag keys and values are case-sensitive.
            Do not use aws:, AWS:, or any upper or lowercase combination of such as a prefix for either keys
            or values as it is reserved for Amazon Web Services use. You cannot edit or delete tag keys or
            values with this prefix. Tags with this prefix do not count against your tags per resource
            limit. Defaults to None.
        enable_ecs_managed_tags(bool, optional): Specifies whether to enable Amazon ECS managed tags for the tasks within the service. For more
            information, see Tagging Your Amazon ECS Resources in the Amazon Elastic Container Service
            Developer Guide. Defaults to None.
        propagate_tags(Text, optional): Specifies whether to propagate the tags from the task definition or the service to the tasks in
            the service. If no value is specified, the tags are not propagated. Tags can only be propagated
            to the tasks within the service during service creation. To add tags to a task after service
            creation, use the TagResource API action. Defaults to None.
        enable_execute_command(bool, optional): Whether or not the execute command functionality is enabled for the service. If true, this
            enables execute command functionality on all containers in the service tasks. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.ecs.service.present:
                - name: value
                - service_name: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.ecs.service.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.ecs.describe_services(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.ecs.create_service(
                ctx,
                
                
                **{"cluster": cluster, "serviceName": service_name, "taskDefinition": task_definition, "loadBalancers": load_balancers, "serviceRegistries": service_registries, "desiredCount": desired_count, "clientToken": client_token, "launchType": launch_type, "capacityProviderStrategy": capacity_provider_strategy, "platformVersion": platform_version, "role": role, "deploymentConfiguration": deployment_configuration, "placementConstraints": placement_constraints, "placementStrategy": placement_strategy, "networkConfiguration": network_configuration, "healthCheckGracePeriodSeconds": health_check_grace_period_seconds, "schedulingStrategy": scheduling_strategy, "deploymentController": deployment_controller, "tags": tags, "enableECSManagedTags": enable_ecs_managed_tags, "propagateTags": propagate_tags, "enableExecuteCommand": enable_execute_command}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.ecs.describe_services(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, service: Text, cluster: Text = None, force: bool = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes a specified service within a cluster. You can delete a service if you have no running tasks in it and
    the desired task count is zero. If the service is actively maintaining tasks, you cannot delete it, and you must
    update the service to a desired task count of zero. For more information, see UpdateService.  When you delete a
    service, if there are still running tasks that require cleanup, the service status moves from ACTIVE to
    DRAINING, and the service is no longer visible in the console or in the ListServices API operation. After all
    tasks have transitioned to either STOPPING or STOPPED status, the service status moves from DRAINING to
    INACTIVE. Services in the DRAINING or INACTIVE status can still be viewed with the DescribeServices API
    operation. However, in the future, INACTIVE services may be cleaned up and purged from Amazon ECS record
    keeping, and DescribeServices calls on those services return a ServiceNotFoundException error.   If you attempt
    to create a new service with the same name as an existing service in either ACTIVE or DRAINING status, you
    receive an error.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        cluster(Text, optional): The short name or full Amazon Resource Name (ARN) of the cluster that hosts the service to
            delete. If you do not specify a cluster, the default cluster is assumed. Defaults to None.
        service(Text): The name of the service to delete.
        force(bool, optional): If true, allows you to delete a service even if it has not been scaled down to zero tasks. It is
            only necessary to use this if the service is using the REPLICA scheduling strategy. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.ecs.service.absent:
                - name: value
                - service: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.ecs.service.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.ecs.describe_services(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.ecs.delete_service(
                ctx,
                
                
                **{"cluster": cluster, "service": service, "force": force}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.ecs.describe_services(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

