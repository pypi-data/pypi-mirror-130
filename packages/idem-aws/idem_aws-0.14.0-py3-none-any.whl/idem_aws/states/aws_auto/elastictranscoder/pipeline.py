"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.elastictranscoder.create_pipeline
hub.exec.boto3.client.elastictranscoder.delete_pipeline
hub.exec.boto3.client.elastictranscoder.list_pipelines
hub.exec.boto3.client.elastictranscoder.read_pipeline
hub.exec.boto3.client.elastictranscoder.update_pipeline
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, input_bucket: Text, role: Text, output_bucket: Text = None, aws_kms_key_arn: Text = None, notifications: Dict = None, content_config: Dict = None, thumbnail_config: Dict = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    The CreatePipeline operation creates a pipeline with settings that you specify.

    Args:
        name(Text): The name of the pipeline. We recommend that the name be unique within the AWS account, but
            uniqueness is not enforced. Constraints: Maximum 40 characters.
        input_bucket(Text): The Amazon S3 bucket in which you saved the media files that you want to transcode.
        output_bucket(Text, optional): The Amazon S3 bucket in which you want Elastic Transcoder to save the transcoded files. (Use
            this, or use ContentConfig:Bucket plus ThumbnailConfig:Bucket.) Specify this value when all of
            the following are true:   You want to save transcoded files, thumbnails (if any), and playlists
            (if any) together in one bucket.   You do not want to specify the users or groups who have
            access to the transcoded files, thumbnails, and playlists.   You do not want to specify the
            permissions that Elastic Transcoder grants to the files.   When Elastic Transcoder saves files
            in OutputBucket, it grants full control over the files only to the AWS account that owns the
            role that is specified by Role.    You want to associate the transcoded files and thumbnails
            with the Amazon S3 Standard storage class.   If you want to save transcoded files and playlists
            in one bucket and thumbnails in another bucket, specify which users can access the transcoded
            files or the permissions the users have, or change the Amazon S3 storage class, omit
            OutputBucket and specify values for ContentConfig and ThumbnailConfig instead. Defaults to None.
        role(Text): The IAM Amazon Resource Name (ARN) for the role that you want Elastic Transcoder to use to
            create the pipeline.
        aws_kms_key_arn(Text, optional): The AWS Key Management Service (AWS KMS) key that you want to use with this pipeline. If you use
            either s3 or s3-aws-kms as your Encryption:Mode, you don't need to provide a key with your job
            because a default key, known as an AWS-KMS key, is created for you automatically. You need to
            provide an AWS-KMS key only if you want to use a non-default AWS-KMS key, or if you are using an
            Encryption:Mode of aes-cbc-pkcs7, aes-ctr, or aes-gcm. Defaults to None.
        notifications(Dict, optional): The Amazon Simple Notification Service (Amazon SNS) topic that you want to notify to report job
            status.  To receive notifications, you must also subscribe to the new topic in the Amazon SNS
            console.     Progressing: The topic ARN for the Amazon Simple Notification Service (Amazon SNS)
            topic that you want to notify when Elastic Transcoder has started to process a job in this
            pipeline. This is the ARN that Amazon SNS returned when you created the topic. For more
            information, see Create a Topic in the Amazon Simple Notification Service Developer Guide.
            Complete: The topic ARN for the Amazon SNS topic that you want to notify when Elastic Transcoder
            has finished processing a job in this pipeline. This is the ARN that Amazon SNS returned when
            you created the topic.    Warning: The topic ARN for the Amazon SNS topic that you want to
            notify when Elastic Transcoder encounters a warning condition while processing a job in this
            pipeline. This is the ARN that Amazon SNS returned when you created the topic.    Error: The
            topic ARN for the Amazon SNS topic that you want to notify when Elastic Transcoder encounters an
            error condition while processing a job in this pipeline. This is the ARN that Amazon SNS
            returned when you created the topic. Defaults to None.
        content_config(Dict, optional): The optional ContentConfig object specifies information about the Amazon S3 bucket in which you
            want Elastic Transcoder to save transcoded files and playlists: which bucket to use, which users
            you want to have access to the files, the type of access you want users to have, and the storage
            class that you want to assign to the files. If you specify values for ContentConfig, you must
            also specify values for ThumbnailConfig. If you specify values for ContentConfig and
            ThumbnailConfig, omit the OutputBucket object.    Bucket: The Amazon S3 bucket in which you want
            Elastic Transcoder to save transcoded files and playlists.    Permissions (Optional): The
            Permissions object specifies which users you want to have access to transcoded files and the
            type of access you want them to have. You can grant permissions to a maximum of 30 users and/or
            predefined Amazon S3 groups.    Grantee Type: Specify the type of value that appears in the
            Grantee object:     Canonical: The value in the Grantee object is either the canonical user ID
            for an AWS account or an origin access identity for an Amazon CloudFront distribution. For more
            information about canonical user IDs, see Access Control List (ACL) Overview in the Amazon
            Simple Storage Service Developer Guide. For more information about using CloudFront origin
            access identities to require that users use CloudFront URLs instead of Amazon S3 URLs, see Using
            an Origin Access Identity to Restrict Access to Your Amazon S3 Content.  A canonical user ID is
            not the same as an AWS account number.     Email: The value in the Grantee object is the
            registered email address of an AWS account.    Group: The value in the Grantee object is one of
            the following predefined Amazon S3 groups: AllUsers, AuthenticatedUsers, or LogDelivery.
            Grantee: The AWS user or group that you want to have access to transcoded files and playlists.
            To identify the user or group, you can specify the canonical user ID for an AWS account, an
            origin access identity for a CloudFront distribution, the registered email address of an AWS
            account, or a predefined Amazon S3 group     Access: The permission that you want to give to the
            AWS user that you specified in Grantee. Permissions are granted on the files that Elastic
            Transcoder adds to the bucket, including playlists and video files. Valid values include:
            READ: The grantee can read the objects and metadata for objects that Elastic Transcoder adds to
            the Amazon S3 bucket.    READ_ACP: The grantee can read the object ACL for objects that Elastic
            Transcoder adds to the Amazon S3 bucket.    WRITE_ACP: The grantee can write the ACL for the
            objects that Elastic Transcoder adds to the Amazon S3 bucket.    FULL_CONTROL: The grantee has
            READ, READ_ACP, and WRITE_ACP permissions for the objects that Elastic Transcoder adds to the
            Amazon S3 bucket.      StorageClass: The Amazon S3 storage class, Standard or ReducedRedundancy,
            that you want Elastic Transcoder to assign to the video files and playlists that it stores in
            your Amazon S3 bucket. Defaults to None.
        thumbnail_config(Dict, optional): The ThumbnailConfig object specifies several values, including the Amazon S3 bucket in which you
            want Elastic Transcoder to save thumbnail files, which users you want to have access to the
            files, the type of access you want users to have, and the storage class that you want to assign
            to the files. If you specify values for ContentConfig, you must also specify values for
            ThumbnailConfig even if you don't want to create thumbnails. If you specify values for
            ContentConfig and ThumbnailConfig, omit the OutputBucket object.    Bucket: The Amazon S3 bucket
            in which you want Elastic Transcoder to save thumbnail files.    Permissions (Optional): The
            Permissions object specifies which users and/or predefined Amazon S3 groups you want to have
            access to thumbnail files, and the type of access you want them to have. You can grant
            permissions to a maximum of 30 users and/or predefined Amazon S3 groups.    GranteeType: Specify
            the type of value that appears in the Grantee object:     Canonical: The value in the Grantee
            object is either the canonical user ID for an AWS account or an origin access identity for an
            Amazon CloudFront distribution.  A canonical user ID is not the same as an AWS account number.
            Email: The value in the Grantee object is the registered email address of an AWS account.
            Group: The value in the Grantee object is one of the following predefined Amazon S3 groups:
            AllUsers, AuthenticatedUsers, or LogDelivery.      Grantee: The AWS user or group that you want
            to have access to thumbnail files. To identify the user or group, you can specify the canonical
            user ID for an AWS account, an origin access identity for a CloudFront distribution, the
            registered email address of an AWS account, or a predefined Amazon S3 group.     Access: The
            permission that you want to give to the AWS user that you specified in Grantee. Permissions are
            granted on the thumbnail files that Elastic Transcoder adds to the bucket. Valid values include:
            READ: The grantee can read the thumbnails and metadata for objects that Elastic Transcoder adds
            to the Amazon S3 bucket.    READ_ACP: The grantee can read the object ACL for thumbnails that
            Elastic Transcoder adds to the Amazon S3 bucket.    WRITE_ACP: The grantee can write the ACL for
            the thumbnails that Elastic Transcoder adds to the Amazon S3 bucket.    FULL_CONTROL: The
            grantee has READ, READ_ACP, and WRITE_ACP permissions for the thumbnails that Elastic Transcoder
            adds to the Amazon S3 bucket.      StorageClass: The Amazon S3 storage class, Standard or
            ReducedRedundancy, that you want Elastic Transcoder to assign to the thumbnails that it stores
            in your Amazon S3 bucket. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.elastictranscoder.pipeline.present:
                - name: value
                - input_bucket: value
                - role: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.elastictranscoder.pipeline.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.elastictranscoder.list_pipelines(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.elastictranscoder.create_pipeline(
                ctx,
                
                
                **{"Name": name, "InputBucket": input_bucket, "OutputBucket": output_bucket, "Role": role, "AwsKmsKeyArn": aws_kms_key_arn, "Notifications": notifications, "ContentConfig": content_config, "ThumbnailConfig": thumbnail_config}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.elastictranscoder.list_pipelines(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, id_: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    The DeletePipeline operation removes a pipeline.  You can only delete a pipeline that has never been used or
    that is not currently in use (doesn't contain any active jobs). If the pipeline is currently in use,
    DeletePipeline returns an error.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        id_(Text): The identifier of the pipeline that you want to delete.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.elastictranscoder.pipeline.absent:
                - name: value
                - id_: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.elastictranscoder.pipeline.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.elastictranscoder.list_pipelines(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.elastictranscoder.delete_pipeline(
                ctx,
                
                
                **{"Id": id_}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.elastictranscoder.list_pipelines(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

