"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.batch.create_compute_environment
hub.exec.boto3.client.batch.delete_compute_environment
hub.exec.boto3.client.batch.describe_compute_environments
hub.exec.boto3.client.batch.update_compute_environment
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, compute_environment_name: Text, type_: Text, state: Text = None, compute_resources: Dict = None, service_role: Text = None, tags: Dict = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates an Batch compute environment. You can create MANAGED or UNMANAGED compute environments. MANAGED compute
    environments can use Amazon EC2 or Fargate resources. UNMANAGED compute environments can only use EC2 resources.
    In a managed compute environment, Batch manages the capacity and instance types of the compute resources within
    the environment. This is based on the compute resource specification that you define or the launch template that
    you specify when you create the compute environment. Either, you can choose to use EC2 On-Demand Instances and
    EC2 Spot Instances. Or, you can use Fargate and Fargate Spot capacity in your managed compute environment. You
    can optionally set a maximum price so that Spot Instances only launch when the Spot Instance price is less than
    a specified percentage of the On-Demand price.  Multi-node parallel jobs aren't supported on Spot Instances.  In
    an unmanaged compute environment, you can manage your own EC2 compute resources and have a lot of flexibility
    with how you configure your compute resources. For example, you can use custom AMIs. However, you must verify
    that each of your AMIs meet the Amazon ECS container instance AMI specification. For more information, see
    container instance AMIs in the Amazon Elastic Container Service Developer Guide. After you created your
    unmanaged compute environment, you can use the DescribeComputeEnvironments operation to find the Amazon ECS
    cluster that's associated with it. Then, launch your container instances into that Amazon ECS cluster. For more
    information, see Launching an Amazon ECS container instance in the Amazon Elastic Container Service Developer
    Guide.  Batch doesn't upgrade the AMIs in a compute environment after the environment is created. For example,
    it doesn't update the AMIs when a newer version of the Amazon ECS optimized AMI is available. Therefore, you're
    responsible for managing the guest operating system (including its updates and security patches) and any
    additional application software or utilities that you install on the compute resources. To use a new AMI for
    your Batch jobs, complete these steps:   Create a new compute environment with the new AMI.   Add the compute
    environment to an existing job queue.   Remove the earlier compute environment from your job queue.   Delete the
    earlier compute environment.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        compute_environment_name(Text): The name for your compute environment. Up to 128 letters (uppercase and lowercase), numbers,
            hyphens, and underscores are allowed.
        type_(Text): The type of the compute environment: MANAGED or UNMANAGED. For more information, see Compute
            Environments in the Batch User Guide.
        state(Text, optional): The state of the compute environment. If the state is ENABLED, then the compute environment
            accepts jobs from a queue and can scale out automatically based on queues. If the state is
            ENABLED, then the Batch scheduler can attempt to place jobs from an associated job queue on the
            compute resources within the environment. If the compute environment is managed, then it can
            scale its instances out or in automatically, based on the job queue demand. If the state is
            DISABLED, then the Batch scheduler doesn't attempt to place jobs within the environment. Jobs in
            a STARTING or RUNNING state continue to progress normally. Managed compute environments in the
            DISABLED state don't scale out. However, they scale in to minvCpus value after instances become
            idle. Defaults to None.
        compute_resources(Dict, optional): Details about the compute resources managed by the compute environment. This parameter is
            required for managed compute environments. For more information, see Compute Environments in the
            Batch User Guide. Defaults to None.
        service_role(Text, optional): The full Amazon Resource Name (ARN) of the IAM role that allows Batch to make calls to other
            Amazon Web Services services on your behalf. For more information, see Batch service IAM role in
            the Batch User Guide.  If your account already created the Batch service-linked role, that role
            is used by default for your compute environment unless you specify a different role here. If the
            Batch service-linked role doesn't exist in your account, and no role is specified here, the
            service attempts to create the Batch service-linked role in your account.  If your specified
            role has a path other than /, then you must specify either the full role ARN (recommended) or
            prefix the role name with the path. For example, if a role with the name bar has a path of /foo/
            then you would specify /foo/bar as the role name. For more information, see Friendly names and
            paths in the IAM User Guide.  Depending on how you created your Batch service role, its ARN
            might contain the service-role path prefix. When you only specify the name of the service role,
            Batch assumes that your ARN doesn't use the service-role path prefix. Because of this, we
            recommend that you specify the full ARN of your service role when you create compute
            environments. Defaults to None.
        tags(Dict, optional): The tags that you apply to the compute environment to help you categorize and organize your
            resources. Each tag consists of a key and an optional value. For more information, see Tagging
            Amazon Web Services Resources in Amazon Web Services General Reference. These tags can be
            updated or removed using the TagResource and UntagResource API operations. These tags don't
            propagate to the underlying compute resources. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.batch.compute_environment.present:
                - name: value
                - compute_environment_name: value
                - type_: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.batch.compute_environment.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.batch.describe_compute_environments(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.batch.create_compute_environment(
                ctx,
                
                
                **{"computeEnvironmentName": compute_environment_name, "type": type_, "state": state, "computeResources": compute_resources, "serviceRole": service_role, "tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.batch.describe_compute_environments(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, compute_environment: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes an Batch compute environment. Before you can delete a compute environment, you must set its state to
    DISABLED with the UpdateComputeEnvironment API operation and disassociate it from any job queues with the
    UpdateJobQueue API operation. Compute environments that use Fargate resources must terminate all active jobs on
    that compute environment before deleting the compute environment. If this isn't done, the compute environment
    enters an invalid state.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        compute_environment(Text): The name or Amazon Resource Name (ARN) of the compute environment to delete.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.batch.compute_environment.absent:
                - name: value
                - compute_environment: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.batch.compute_environment.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.batch.describe_compute_environments(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.batch.delete_compute_environment(
                ctx,
                
                
                **{"computeEnvironment": compute_environment}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.batch.describe_compute_environments(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

