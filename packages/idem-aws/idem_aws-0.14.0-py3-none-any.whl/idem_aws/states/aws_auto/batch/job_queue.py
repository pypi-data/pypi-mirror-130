"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.batch.create_job_queue
hub.exec.boto3.client.batch.delete_job_queue
hub.exec.boto3.client.batch.describe_job_queues
hub.exec.boto3.client.batch.update_job_queue
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, job_queue_name: Text, priority: int, compute_environment_order: List, state: Text = None, tags: Dict = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates an Batch job queue. When you create a job queue, you associate one or more compute environments to the
    queue and assign an order of preference for the compute environments. You also set a priority to the job queue
    that determines the order that the Batch scheduler places jobs onto its associated compute environments. For
    example, if a compute environment is associated with more than one job queue, the job queue with a higher
    priority is given preference for scheduling jobs to that compute environment.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        job_queue_name(Text): The name of the job queue. Up to 128 letters (uppercase and lowercase), numbers, and underscores
            are allowed.
        state(Text, optional): The state of the job queue. If the job queue state is ENABLED, it is able to accept jobs. If the
            job queue state is DISABLED, new jobs can't be added to the queue, but jobs already in the queue
            can finish. Defaults to None.
        priority(int): The priority of the job queue. Job queues with a higher priority (or a higher integer value for
            the priority parameter) are evaluated first when associated with the same compute environment.
            Priority is determined in descending order. For example, a job queue with a priority value of 10
            is given scheduling preference over a job queue with a priority value of 1. All of the compute
            environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT); EC2 and
            Fargate compute environments can't be mixed.
        compute_environment_order(List): The set of compute environments mapped to a job queue and their order relative to each other.
            The job scheduler uses this parameter to determine which compute environment should run a
            specific job. Compute environments must be in the VALID state before you can associate them with
            a job queue. You can associate up to three compute environments with a job queue. All of the
            compute environments must be either EC2 (EC2 or SPOT) or Fargate (FARGATE or FARGATE_SPOT); EC2
            and Fargate compute environments can't be mixed.  All compute environments that are associated
            with a job queue must share the same architecture. Batch doesn't support mixing compute
            environment architecture types in a single job queue.
        tags(Dict, optional): The tags that you apply to the job queue to help you categorize and organize your resources.
            Each tag consists of a key and an optional value. For more information, see Tagging your Batch
            resources in Batch User Guide. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.batch.job_queue.present:
                - name: value
                - job_queue_name: value
                - priority: value
                - compute_environment_order: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.batch.job_queue.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.batch.describe_job_queues(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.batch.create_job_queue(
                ctx,
                
                
                **{"jobQueueName": job_queue_name, "state": state, "priority": priority, "computeEnvironmentOrder": compute_environment_order, "tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.batch.describe_job_queues(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, job_queue: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes the specified job queue. You must first disable submissions for a queue with the UpdateJobQueue
    operation. All jobs in the queue are eventually terminated when you delete a job queue. The jobs are terminated
    at a rate of about 16 jobs each second. It's not necessary to disassociate compute environments from a queue
    before submitting a DeleteJobQueue request.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        job_queue(Text): The short name or full Amazon Resource Name (ARN) of the queue to delete.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.batch.job_queue.absent:
                - name: value
                - job_queue: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.batch.job_queue.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.batch.describe_job_queues(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.batch.delete_job_queue(
                ctx,
                
                
                **{"jobQueue": job_queue}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.batch.describe_job_queues(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

