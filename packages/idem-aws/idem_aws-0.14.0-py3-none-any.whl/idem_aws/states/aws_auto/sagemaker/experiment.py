"""
Autogenerated state module using `pop-create-idem <https://gitlab.com/saltstack/pop/pop-create-idem>`__

hub.exec.boto3.client.sagemaker.create_experiment
hub.exec.boto3.client.sagemaker.delete_experiment
hub.exec.boto3.client.sagemaker.describe_experiment
hub.exec.boto3.client.sagemaker.list_experiments
hub.exec.boto3.client.sagemaker.update_experiment
"""



from typing import *
import dict_tools.differ as differ
async def present(hub, ctx, name: Text, experiment_name: Text, display_name: Text = None, description: Text = None, tags: List = None)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Creates an SageMaker experiment. An experiment is a collection of trials that are observed, compared and
    evaluated as a group. A trial is a set of steps, called trial components, that produce a machine learning model.
    The goal of an experiment is to determine the components that produce the best model. Multiple trials are
    performed, each one isolating and measuring the impact of a change to one or more inputs, while keeping the
    remaining inputs constant. When you use SageMaker Studio or the SageMaker Python SDK, all experiments, trials,
    and trial components are automatically tracked, logged, and indexed. When you use the Amazon Web Services SDK
    for Python (Boto), you must use the logging APIs provided by the SDK. You can add tags to experiments, trials,
    trial components and then use the Search API to search for the tags. To add a description to an experiment,
    specify the optional Description parameter. To add a description later, or to change the description, call the
    UpdateExperiment API. To get a list of all your experiments, call the ListExperiments API. To view an
    experiment's properties, call the DescribeExperiment API. To get a list of all the trials associated with an
    experiment, call the ListTrials API. To create a trial call the CreateTrial API.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        experiment_name(Text): The name of the experiment. The name must be unique in your Amazon Web Services account and is
            not case-sensitive.
        display_name(Text, optional): The name of the experiment as displayed. The name doesn't need to be unique. If you don't
            specify DisplayName, the value in ExperimentName is displayed. Defaults to None.
        description(Text, optional): The description of the experiment. Defaults to None.
        tags(List, optional): A list of tags to associate with the experiment. You can use Search API to search on the tags. Defaults to None.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_present:
              aws_auto.sagemaker.experiment.present:
                - name: value
                - experiment_name: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.sagemaker.experiment.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    
    before = await hub.exec.boto3.client.sagemaker.describe_experiment(name)

    if before:
        result["comment"] = f"'{name}' already exists"
    else:
        try:
            ret = await hub.exec.boto3.client.sagemaker.create_experiment(
                ctx,
                
                
                **{"ExperimentName": experiment_name, "DisplayName": display_name, "Description": description, "Tags": tags}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            ret["comment"] = f"Created '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    
    # TODO perform other modifications as needed here
    ...

    after = await hub.exec.boto3.client.sagemaker.describe_experiment(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

async def absent(hub, ctx, name: Text, experiment_name: Text)  -> Dict[str, Any]:
    r'''
    **Autogenerated function**
    
    Deletes an SageMaker experiment. All trials associated with the experiment must be deleted first. Use the
    ListTrials API to get a list of the trials associated with the experiment.

    Args:
        name(Text): A name, ID, or JMES search path to identify the resource.
        experiment_name(Text): The name of the experiment to delete.

    Returns:
        Dict[str, Any]

    Examples:

        .. code-block:: sls

            resource_is_absent:
              aws_auto.sagemaker.experiment.absent:
                - name: value
                - experiment_name: value
    '''
    
    result = dict(comment="", changes= None, name=name, result=True)
    ret = await hub.exec.boto3.client.sagemaker.experiment.id(
        ctx,
        jmes_path=name
    )
    if ret["status"]:
        # name is now the first id that matched the JMES search path
        name = ret["ret"]
    

    

    before = await hub.exec.boto3.client.sagemaker.describe_experiment(name)

    if not before:
        result["comment"] = f"'{name}' already absent"
    else:
        try:
            ret = await hub.exec.boto3.client.sagemaker.delete_experiment(
                ctx,
                
                
                **{"ExperimentName": experiment_name}
            )
            result["result"] = ret["status"]
            if not result["result"]:
                result["comment"] = ret["comment"]
                return result
            result["comment"] = f"Deleted '{name}'"
        except hub.tool.boto3.exception.ClientError as e:
            result["comment"] = f"{e.__class__.__name__}: {e}"

    

    after = await hub.exec.boto3.client.sagemaker.describe_experiment(name)
    result["changes"] = differ.deep_diff(before, after)
    return result

